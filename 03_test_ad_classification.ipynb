{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install sentence_transformers\n",
    "\n",
    "import nltk\n",
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "model_class = AutoModelForSequenceClassification.from_pretrained('morenolq/spotify-podcast-advertising-classification')\n",
    "tokenizer = AutoTokenizer.from_pretrained('morenolq/spotify-podcast-advertising-classification')\n",
    "\n",
    "# Only run this once, they will be downloaded.\n",
    "nltk.download('stopwords',quiet=True)\n",
    "nltk.download('wordnet',quiet=True)\n",
    "nltk.download('punkt',quiet=True)\n",
    "nltk.download('omw-1.4',quiet=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# morenolq/spotify-podcast-advertising-classification test on Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously indicated episodes to test all chatbots against\n",
    "indicator_episodes = [\"spotify:episode:5fG4VlWnWwzAt6mSs0H7lY\", \"spotify:episode:7JG3lLnRoDdOxuqjf14ZkM\",\n",
    "                            \"spotify:episode:3kkhUQJ9DXYs6aSdDmPp2V\", \"spotify:episode:4fJ6Y6IpljKy8FT8DZHx1L\",\n",
    "                            \"spotify:episode:5xBPWxqVCocdBgybmHjr5V\", \"spotify:episode:0X663c1I6j1cehJvy10WMm\", \n",
    "                            \"spotify:episode:61a1JjZO27lGCvCwBaCkpC\", \"spotify:episode:0goWRy1gwB23rQVy8ci7Wa\", \n",
    "                            \"spotify:episode:0BSD8QYmd2mQ1V43uIrU4I\", \"spotify:episode:5xH3cdpkxnJhQjPV22sxKC\",\n",
    "                            \"spotify:episode:0YPvJfSEw0jacPB3IeT37d\", \"spotify:episode:1gnpv26FFvIxpnwVbbRXv1\",\n",
    "                            \"spotify:episode:6rh4J52THn252yi7t11Yqf\", \"spotify:episode:3IfmcM2rcWb82601pkPvCh\",\n",
    "                            \"spotify:episode:5LJ33LdXWhqOu1KNad6D5q\", \"spotify:episode:1AxFBio6NwwG0MAjdCK5gK\",\n",
    "                            \"spotify:episode:3U33mRnDJcXywmBm1hahlL\", \"spotify:episode:57Nzb9H2VRZgHcNFChwbBG\",\n",
    "                            \"spotify:episode:6vRLNVEQ4xqtMxnms3RZh3\", \"spotify:episode:1tN044BhlPjjiluZ7Wo7UL\",\n",
    "                            \"spotify:episode:1fs86N6FLUKW2e5NdX1dF1\", \"spotify:episode:1A4cHtP3wIVQutpCgS7kd7\",\n",
    "                            \"spotify:episode:1Mi90UjG91rm73qvHzcG0t\", \"spotify:episode:3TuC8HZp9VdXtxYMQkJI0m\",\n",
    "                            \"spotify:episode:67v8V9SOXxivYQfAHSsc5f\", \"spotify:episode:3QE8qxHtJg3zMrq03R4GOj\",\n",
    "                            \"spotify:episode:3Vr6AUCTQgVWoE137b4IdB\", \"spotify:episode:4oQZAcd6xnxVA1e2GWaIFb\",\n",
    "                            \"spotify:episode:4sbSs1xtuf8dF3xtb7btUi\", \"spotify:episode:2RoLspr2PQTki51sfMhd20\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for spotify:episode:5fG4VlWnWwzAt6mSs0H7lY: 13.52 minutes\n",
      "Total time for spotify:episode:7JG3lLnRoDdOxuqjf14ZkM: 9.71 minutes\n",
      "Total time for spotify:episode:3kkhUQJ9DXYs6aSdDmPp2V: 8.1 minutes\n",
      "Total time for spotify:episode:4fJ6Y6IpljKy8FT8DZHx1L: 8.4 minutes\n",
      "Total time for spotify:episode:5xBPWxqVCocdBgybmHjr5V: 10.75 minutes\n",
      "Total time for spotify:episode:0X663c1I6j1cehJvy10WMm: 3.76 minutes\n",
      "Total time for spotify:episode:61a1JjZO27lGCvCwBaCkpC: 9.88 minutes\n",
      "Total time for spotify:episode:0goWRy1gwB23rQVy8ci7Wa: 6.17 minutes\n",
      "Total time for spotify:episode:0BSD8QYmd2mQ1V43uIrU4I: 4.01 minutes\n",
      "Total time for spotify:episode:5xH3cdpkxnJhQjPV22sxKC: 1.93 minutes\n",
      "Total time for spotify:episode:0YPvJfSEw0jacPB3IeT37d: 5.68 minutes\n",
      "Total time for spotify:episode:1gnpv26FFvIxpnwVbbRXv1: 1.35 minutes\n",
      "Total time for spotify:episode:6rh4J52THn252yi7t11Yqf: 7.4 minutes\n",
      "Total time for spotify:episode:3IfmcM2rcWb82601pkPvCh: 1.45 minutes\n",
      "Total time for spotify:episode:5LJ33LdXWhqOu1KNad6D5q: 1.22 minutes\n",
      "Total time for spotify:episode:1AxFBio6NwwG0MAjdCK5gK: 3.55 minutes\n",
      "Total time for spotify:episode:3U33mRnDJcXywmBm1hahlL: 12.25 minutes\n",
      "Total time for spotify:episode:57Nzb9H2VRZgHcNFChwbBG: 2.19 minutes\n",
      "Total time for spotify:episode:6vRLNVEQ4xqtMxnms3RZh3: 4.11 minutes\n",
      "Total time for spotify:episode:1tN044BhlPjjiluZ7Wo7UL: 1.44 minutes\n",
      "Total time for spotify:episode:1fs86N6FLUKW2e5NdX1dF1: 5.64 minutes\n",
      "Total time for spotify:episode:1A4cHtP3wIVQutpCgS7kd7: 10.8 minutes\n",
      "Total time for spotify:episode:1Mi90UjG91rm73qvHzcG0t: 0.31 minutes\n",
      "Total time for spotify:episode:3TuC8HZp9VdXtxYMQkJI0m: 1.5 minutes\n",
      "Total time for spotify:episode:67v8V9SOXxivYQfAHSsc5f: 2.08 minutes\n",
      "Total time for spotify:episode:3QE8qxHtJg3zMrq03R4GOj: 9.23 minutes\n",
      "Total time for spotify:episode:3Vr6AUCTQgVWoE137b4IdB: 6.65 minutes\n",
      "Total time for spotify:episode:4oQZAcd6xnxVA1e2GWaIFb: 3.44 minutes\n",
      "Total time for spotify:episode:4sbSs1xtuf8dF3xtb7btUi: 5.49 minutes\n",
      "Total time for spotify:episode:2RoLspr2PQTki51sfMhd20: 3.79 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "of_interest = []\n",
    "\n",
    "for episode in indicator_episodes:\n",
    "    episode_ = {\n",
    "        \"query\": {\n",
    "            \"match_phrase\": {\n",
    "                \"_id\": episode,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    results = es.search(index=\"spotify_podcast_transcripts\", body=episode_)\n",
    "\n",
    "    # Extract relevant information from the search results\n",
    "    hits = results[\"hits\"][\"hits\"]\n",
    "\n",
    "    if hits:\n",
    "        episode_uri = hits[0]['_id']\n",
    "        sentences = hits[0]['_source']['sentence_tokens']\n",
    "\n",
    "        # sentence_outputs_tuples = []\n",
    "\n",
    "        # Iterate through each sentence in the transcript\n",
    "        # If the sentence is an advertisement, add it to the list of advertisements\n",
    "        ad_sentences = []\n",
    "        probabilities = []\n",
    "        start = time.time()\n",
    "\n",
    "        # Iterate through each sentence in the transcript\n",
    "        for i, s in enumerate(sentences):\n",
    "\n",
    "            # If the sentence is an advertisement, add it to the list of advertisements \n",
    "            if i==0:\n",
    "                context = \"__START__\"\n",
    "\n",
    "            # If the sentence is not an advertisement, add it to the list of non-advertisements    \n",
    "            else:\n",
    "                # Get the context of the sentence\n",
    "                context = sentences[i-1]\n",
    "\n",
    "            # Get the probability of the sentence being an advertisement \n",
    "            out = tokenizer(context,\n",
    "                            s, padding = \"max_length\", max_length = 256,truncation=True,\n",
    "                            return_attention_mask=True, return_tensors = 'pt')\n",
    "            \n",
    "            # Get the model's prediction for the sentence\n",
    "            outputs = model_class(**out)\n",
    "\n",
    "            # Get the probabilities of the sentence being an advertisement\n",
    "            probabilities_ = F.softmax(outputs.logits, dim=1)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "            # If the model predicts the sentence is an advertisement, add it to the list of advertisements\n",
    "            if predictions.item() == 1:\n",
    "                ad_sentences.append(s)\n",
    "                probabilities.append(probabilities_.tolist()[0][1])\n",
    "\n",
    "        end = time.time()\n",
    "        total_time = round((end-start)/60, 2)\n",
    "        print(f\"Total time for {episode_uri}: {total_time} minutes\")\n",
    "\n",
    "        episode_info = pd.DataFrame({\n",
    "            \"episode_uri\": episode_uri,\n",
    "            \"top_responses\": ad_sentences,\n",
    "            \"top_scores\": probabilities,\n",
    "            \"total_time\": total_time\n",
    "            })        \n",
    "        of_interest.append(episode_info)\n",
    "\n",
    "## Create a DataFrame from the list of episode information\n",
    "# indicator_episodes_df = pd.DataFrame(of_interest)\n",
    "# indicator_episodes_df\n",
    "\n",
    "len(of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_uri</th>\n",
       "      <th>top_responses</th>\n",
       "      <th>top_scores</th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:episode:5fG4VlWnWwzAt6mSs0H7lY</td>\n",
       "      <td>So download the free anchor app or go to Ancho...</td>\n",
       "      <td>0.523892</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:episode:5fG4VlWnWwzAt6mSs0H7lY</td>\n",
       "      <td>F m-- to get started.</td>\n",
       "      <td>0.872203</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:episode:5fG4VlWnWwzAt6mSs0H7lY</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>0.560135</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:episode:5fG4VlWnWwzAt6mSs0H7lY</td>\n",
       "      <td>It's been a long.</td>\n",
       "      <td>0.525132</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:episode:5fG4VlWnWwzAt6mSs0H7lY</td>\n",
       "      <td>I don't think it's that important.</td>\n",
       "      <td>0.561293</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spotify:episode:5fG4VlWnWwzAt6mSs0H7lY</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>0.747715</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spotify:episode:5fG4VlWnWwzAt6mSs0H7lY</td>\n",
       "      <td>I just kind of wish it so that's where we got ...</td>\n",
       "      <td>0.551299</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spotify:episode:5fG4VlWnWwzAt6mSs0H7lY</td>\n",
       "      <td>It was weird.</td>\n",
       "      <td>0.512934</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spotify:episode:5fG4VlWnWwzAt6mSs0H7lY</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>0.590432</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spotify:episode:5fG4VlWnWwzAt6mSs0H7lY</td>\n",
       "      <td>Yeah the majority.</td>\n",
       "      <td>0.531590</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spotify:episode:5fG4VlWnWwzAt6mSs0H7lY</td>\n",
       "      <td>I'm right, of course.</td>\n",
       "      <td>0.517424</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spotify:episode:5fG4VlWnWwzAt6mSs0H7lY</td>\n",
       "      <td>What were they called?</td>\n",
       "      <td>0.555346</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spotify:episode:5fG4VlWnWwzAt6mSs0H7lY</td>\n",
       "      <td>Every single time.</td>\n",
       "      <td>0.537135</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>spotify:episode:5fG4VlWnWwzAt6mSs0H7lY</td>\n",
       "      <td>Yeah, we'd be nasty and we'd go up like I reme...</td>\n",
       "      <td>0.553944</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               episode_uri  \\\n",
       "0   spotify:episode:5fG4VlWnWwzAt6mSs0H7lY   \n",
       "1   spotify:episode:5fG4VlWnWwzAt6mSs0H7lY   \n",
       "2   spotify:episode:5fG4VlWnWwzAt6mSs0H7lY   \n",
       "3   spotify:episode:5fG4VlWnWwzAt6mSs0H7lY   \n",
       "4   spotify:episode:5fG4VlWnWwzAt6mSs0H7lY   \n",
       "5   spotify:episode:5fG4VlWnWwzAt6mSs0H7lY   \n",
       "6   spotify:episode:5fG4VlWnWwzAt6mSs0H7lY   \n",
       "7   spotify:episode:5fG4VlWnWwzAt6mSs0H7lY   \n",
       "8   spotify:episode:5fG4VlWnWwzAt6mSs0H7lY   \n",
       "9   spotify:episode:5fG4VlWnWwzAt6mSs0H7lY   \n",
       "10  spotify:episode:5fG4VlWnWwzAt6mSs0H7lY   \n",
       "11  spotify:episode:5fG4VlWnWwzAt6mSs0H7lY   \n",
       "12  spotify:episode:5fG4VlWnWwzAt6mSs0H7lY   \n",
       "13  spotify:episode:5fG4VlWnWwzAt6mSs0H7lY   \n",
       "\n",
       "                                        top_responses  top_scores  total_time  \n",
       "0   So download the free anchor app or go to Ancho...    0.523892       13.52  \n",
       "1                               F m-- to get started.    0.872203       13.52  \n",
       "2                                               Okay.    0.560135       13.52  \n",
       "3                                   It's been a long.    0.525132       13.52  \n",
       "4                  I don't think it's that important.    0.561293       13.52  \n",
       "5                                                 Hi.    0.747715       13.52  \n",
       "6   I just kind of wish it so that's where we got ...    0.551299       13.52  \n",
       "7                                       It was weird.    0.512934       13.52  \n",
       "8                                               Yeah.    0.590432       13.52  \n",
       "9                                  Yeah the majority.    0.531590       13.52  \n",
       "10                              I'm right, of course.    0.517424       13.52  \n",
       "11                             What were they called?    0.555346       13.52  \n",
       "12                                 Every single time.    0.537135       13.52  \n",
       "13  Yeah, we'd be nasty and we'd go up like I reme...    0.553944       13.52  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview example of identified sentences for one episode\n",
    "of_interest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicator_episodes_df.to_excel('output/classification_indicator_episodes.xlsx', index=False)\n",
    "\n",
    "# Classification per episode\n",
    "index_problem_df = []\n",
    "returned_df = []\n",
    "path = 'output/Indicator_episode_results/classification_per_episode/'\n",
    "\n",
    "# Loop through all the classification results\n",
    "for count, df in enumerate(of_interest):\n",
    "\n",
    "    # Check if the dataframe is empty\n",
    "    if df.shape[0] == 0:\n",
    "\n",
    "        # Add the episode number to the list of episodes without results\n",
    "        index_problem_df.append(count)\n",
    "        continue\n",
    "\n",
    "    # If the dataframe is not empty, add the episode number to the list of episodes with results\n",
    "    else:\n",
    "        # Get the episode URI\n",
    "        episode_uri =df.iloc[0,0]\n",
    "\n",
    "        # Add the episode URI to the list of episodes with results\n",
    "        returned_df.append(episode_uri)\n",
    "\n",
    "        # Save the classification results to an excel file\n",
    "        episode_uri = episode_uri.replace(\":\", \"_\")\n",
    "\n",
    "        # Save the classification results to an excel file\n",
    "        df.to_excel(f'{path}classify_{episode_uri}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 22]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_problem_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New pinecone/distiluse-podcast-nq Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "\n",
    "# episodes whose sentences didn't get classified. spotify:episode:0X663c1I6j1cehJvy10WMm, spotify:episode:1Mi90UjG91rm73qvHzcG0t\n",
    "\n",
    "# load data\n",
    "data = pd.read_excel('output/Indicator_episode_results/classification_indicator_episodes.xlsx', sheet_name=None)\n",
    "data.keys()\n",
    "\n",
    "# get dfs to compare\n",
    "final_dfs = list(data.keys())\n",
    "final_dfs.remove('episode_sentences')\n",
    "final_dfs.remove('episode_sentences_T')\n",
    "final_dfs.remove('raw_output')\n",
    "\n",
    "path = 'output/Indicator_episode_results/'\n",
    "\n",
    "# get ndcg scores for each df\n",
    "scored_dfs = []\n",
    "for episode in final_dfs:\n",
    "\n",
    "    # get df\n",
    "    scored_df = data[episode]\n",
    "\n",
    "    # get y_true\n",
    "    scored_df['y_true'].fillna(0, inplace=True)\n",
    "\n",
    "    # get y_pred\n",
    "    scored_df['top_scores'] = 1\n",
    "    \n",
    "    # get ndcg score\n",
    "    scored_df.sort_values(by=['top_scores'], ascending=False, inplace=True)\n",
    "\n",
    "    # get ndc score\n",
    "    scored_dfs.append(scored_df)\n",
    "\n",
    "ndcg_scores = []\n",
    "\n",
    "# get ndcg score for each df\n",
    "for df in scored_dfs:\n",
    "\n",
    "    # get y_true and y_pred\n",
    "    true_relevance = np.asarray([df['y_true']])\n",
    "\n",
    "    # get y_pred\n",
    "    predicted_scores = np.asarray([df['top_scores']])\n",
    "\n",
    "    # get ndcg score\n",
    "    ndcg = ndcg_score(true_relevance, predicted_scores)\n",
    "    ndcg_scores.append(ndcg)\n",
    "    print(\"NDCG score: \", ndcg)\n",
    "\n",
    "# get average ndcg score\n",
    "avg_ndcg_score = np.mean(ndcg_scores)\n",
    "\n",
    "# For each episode print average score and model \n",
    "model_name = 'pinecone/distiluse-podcast-nq'\n",
    "print('Average NDCG score: ', avg_ndcg_score, \"for model: \", model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Examine classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Sheet30', 'Sheet29', 'Sheet28', 'Sheet27', 'Sheet26', 'Sheet25', 'Sheet24', 'Sheet23', 'Sheet22', 'raw_output', 'Sheet21', 'Sheet20', 'Sheet19', 'Sheet18', 'Sheet17', 'Sheet16', 'Sheet15', 'Sheet14', 'Sheet13', 'Sheet12', 'Sheet11', 'Sheet10', 'Sheet9', 'Sheet8', 'Sheet7', 'Sheet6', 'Sheet5', 'Sheet4', 'Sheet3', 'Sheet2', 'Sheet1', 'episode_sentences', 'episode_sentences_T'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# episodes whose sentences didn't get classified. spotify:episode:0X663c1I6j1cehJvy10WMm, spotify:episode:1Mi90UjG91rm73qvHzcG0t\n",
    "data = pd.read_excel('output/Indicator_episode_results/classification_indicator_episodes.xlsx', sheet_name=None)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the resulting data from episodes\n",
    "final_dfs = list(data.keys())\n",
    "final_dfs.remove('episode_sentences')\n",
    "final_dfs.remove('episode_sentences_T')\n",
    "final_dfs.remove('raw_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_uri</th>\n",
       "      <th>human_identified</th>\n",
       "      <th>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oh that's my age.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Okay you got that.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I can it's so but it's  Really a for it's afte...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm here.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>spotify:episode:3Vr6AUCTQgVWoE137b4IdB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               episode_uri  human_identified  \\\n",
       "0   spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "1   spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "2   spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "3   spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "4   spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "5   spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "6   spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "7   spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "8   spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "9   spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "10  spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "11  spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "12  spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "13  spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "14  spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "15  spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "16  spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "17  spotify:episode:3Vr6AUCTQgVWoE137b4IdB               NaN   \n",
       "\n",
       "               spotify:episode:3Vr6AUCTQgVWoE137b4IdB  y_true  \n",
       "0                                   Oh that's my age.     0.0  \n",
       "1                                  Okay you got that.     0.0  \n",
       "2   I can it's so but it's  Really a for it's afte...     0.0  \n",
       "3                                               Yeah.     0.0  \n",
       "4                                           I'm here.     0.0  \n",
       "5                                               Yeah.     0.0  \n",
       "6                                                 NaN     NaN  \n",
       "7                                                 NaN     NaN  \n",
       "8                                                 NaN     NaN  \n",
       "9                                                 NaN     NaN  \n",
       "10                                                NaN     NaN  \n",
       "11                                                NaN     NaN  \n",
       "12                                                NaN     NaN  \n",
       "13                                                NaN     NaN  \n",
       "14                                                NaN     NaN  \n",
       "15                                                NaN     NaN  \n",
       "16                                                NaN     NaN  \n",
       "17                                                NaN     NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sheet27']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'output/Indicator_episode_results/'\n",
    "\n",
    "scored_dfs = []\n",
    "\n",
    "# go through each episode\n",
    "for episode in final_dfs:\n",
    "    scored_df = data[episode]\n",
    "\n",
    "    # episode_uri = scored_df.iloc[0,0]\n",
    "    # print(episode, episode_uri)\n",
    "\n",
    "    # display(scored_df.head(2))\n",
    "\n",
    "    # if empty score, impute 0\n",
    "    scored_df['y_true'].fillna(0, inplace=True)\n",
    "\n",
    "    # get top scores\n",
    "    scored_df['top_scores'] = 1\n",
    "    \n",
    "    # sort scores\n",
    "    scored_df.sort_values(by=['top_scores'], ascending=False, inplace=True)\n",
    "    scored_dfs.append(scored_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.4169134448340216\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.44836183544011915\n",
      "NDCG score:  0.44836183544011915\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.44836183544011915\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.3656233288925999\n",
      "NDCG score:  0.3656233288925999\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.3656233288925999\n",
      "NDCG score:  0.3656233288925999\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.4169134448340216\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.3656233288925999\n",
      "NDCG score:  0.44836183544011915\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.44836183544011915\n",
      "NDCG score:  0.4169134448340216\n",
      "Average NDCG score:  0.1773555385388553 for model:  morenolq/spotify-podcast-advertising-classification\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "\n",
    "model = 'morenolq/spotify-podcast-advertising-classification'\n",
    "\n",
    "# ordered greatest to least\n",
    "ndcg_scores = []\n",
    "\n",
    "# loat scored data outputs\n",
    "for df in scored_dfs:\n",
    "\n",
    "    # get the episode uri\n",
    "    episode_uri = df.iloc[0,0]\n",
    "\n",
    "    # get the true relevance\n",
    "    true_relevance = np.asarray([df['y_true']])\n",
    "    \n",
    "    try:\n",
    "        predicted_scores = np.asarray([df['top_scores']])\n",
    "        ndcg = ndcg_score(true_relevance, predicted_scores)\n",
    "    except ValueError as error:\n",
    "        print(error)\n",
    "        print(\"Episode URI: \", episode_uri)\n",
    "        continue\n",
    "\n",
    "    \n",
    "    ndcg_scores.append(ndcg)\n",
    "    print(\"NDCG score: \", ndcg)\n",
    "\n",
    "avg_ndcg_score = np.mean(ndcg_scores)\n",
    "print('Average NDCG score: ', avg_ndcg_score, \"for model: \", model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "676"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(\"output/test_transcripts.csv\")\n",
    "test_1_transcript = results.loc[1, 'transcript']\n",
    "sent_tokens = nltk.sent_tokenize(test_1_transcript)# converts to list of sentences\n",
    "len(sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m\n\u001b[0;32m      7\u001b[0m     context \u001b[39m=\u001b[39m sent_tokens[i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \n\u001b[0;32m      8\u001b[0m out \u001b[39m=\u001b[39m tokenizer(context,\n\u001b[0;32m      9\u001b[0m                 s,\n\u001b[0;32m     10\u001b[0m                 padding \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 return_attention_mask\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m                 return_tensors \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m outputs \u001b[39m=\u001b[39m model_class(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mout)\n\u001b[0;32m     17\u001b[0m \u001b[39m# probabilities = F.softmax(outputs.logits, dim=1)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m predictions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(outputs\u001b[39m.\u001b[39mlogits, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Olivia\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Olivia\\anaconda3\\envs\\py38\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1502\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1494\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1495\u001b[0m \u001b[39mlabels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\u001b[39;00m\n\u001b[0;32m   1496\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m    config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39m    If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1502\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[0;32m   1503\u001b[0m     input_ids,\n\u001b[0;32m   1504\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1505\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1506\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1507\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1508\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1509\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1510\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1511\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1512\u001b[0m )\n\u001b[0;32m   1514\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[0;32m   1516\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32mc:\\Users\\Olivia\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Olivia\\anaconda3\\envs\\py38\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:971\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    962\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    964\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m    965\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m    966\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    969\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    970\u001b[0m )\n\u001b[1;32m--> 971\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m    972\u001b[0m     embedding_output,\n\u001b[0;32m    973\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m    974\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    975\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    976\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m    977\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m    978\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    979\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    980\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    981\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    982\u001b[0m )\n\u001b[0;32m    983\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    984\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Olivia\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Olivia\\anaconda3\\envs\\py38\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:568\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    559\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    560\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    561\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    565\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    567\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 568\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    569\u001b[0m         hidden_states,\n\u001b[0;32m    570\u001b[0m         attention_mask,\n\u001b[0;32m    571\u001b[0m         layer_head_mask,\n\u001b[0;32m    572\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    573\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    574\u001b[0m         past_key_value,\n\u001b[0;32m    575\u001b[0m         output_attentions,\n\u001b[0;32m    576\u001b[0m     )\n\u001b[0;32m    578\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\Olivia\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Olivia\\anaconda3\\envs\\py38\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:496\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    493\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    494\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 496\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    497\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[0;32m    498\u001b[0m )\n\u001b[0;32m    499\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[0;32m    501\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Olivia\\anaconda3\\envs\\py38\\lib\\site-packages\\transformers\\modeling_utils.py:1995\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m   1993\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[1;32m-> 1995\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[1;32mc:\\Users\\Olivia\\anaconda3\\envs\\py38\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:509\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m    508\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 509\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[0;32m    510\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\Olivia\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Olivia\\anaconda3\\envs\\py38\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:424\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states, input_tensor):\n\u001b[1;32m--> 424\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[0;32m    425\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    426\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32mc:\\Users\\Olivia\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Olivia\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sentence_outputs_tuples = []\n",
    "start = time.time()\n",
    "for i, s in enumerate(sent_tokens[:200]): \n",
    "    if i==0:\n",
    "        context = \"__START__\"\n",
    "    else:\n",
    "        context = sent_tokens[i-1] \n",
    "    out = tokenizer(context,\n",
    "                    s,\n",
    "                    padding = \"max_length\",\n",
    "                    max_length = 256,\n",
    "                    truncation=True,\n",
    "                    return_attention_mask=True,\n",
    "                    return_tensors = 'pt')\n",
    "    outputs = model_class(**out)\n",
    "    \n",
    "    # probabilities = F.softmax(outputs.logits, dim=1)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "    if predictions.item() == 1:\n",
    "        sentence_outputs_tuples.append((s, predictions.item()))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken:\", (end-start)/60, \"minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"What's up, everybody?\", 0),\n",
       " ('Welcome to the in the dome podcast podcast body are you doing hey, how you doing?',\n",
       "  0),\n",
       " (\"I'm pretty good myself.\", 0),\n",
       " ('All right.', 0),\n",
       " ('What do you want to talk about today?', 0),\n",
       " ('We got a breakdown.', 0),\n",
       " (\"I know there's not much stock boat.\", 0),\n",
       " (\"We still haven't broken down the Columbus game, but cardiac / comeback kids come back.\",\n",
       "  0),\n",
       " ('You know what that game room.', 0),\n",
       " ('Okay, I believe off the where we thought we were talking about a couple of episodes ago were talking about house like a toxic relationship and I was starting to get sucked back in.',\n",
       "  0),\n",
       " ('Yep.', 0),\n",
       " (\"And then I think you were to it's like when fully back on board is fully back with the Calgary Flames right now to start that podcast.\",\n",
       "  0),\n",
       " (\"I was like, I'm not I'm not falling for it.\", 0),\n",
       " (\"I've been hurt too many times by these guys, but by the end of that podcast we switched but I was still whatever.\",\n",
       "  0),\n",
       " (\"Yeah, I'm fine.\", 0),\n",
       " (\"I'm told I'm fully back.\", 0),\n",
       " (\"You're fully back.\", 0),\n",
       " (\"I'm proud.\", 0),\n",
       " (\"I'm not fully back.\", 0),\n",
       " (\"They've sucked me in that Columbus game.\", 0),\n",
       " (\"Got me back to being like, I think I'll die for this team.\", 0),\n",
       " ('I think throughout all this up and down.', 0),\n",
       " (\"Really sobered me and to the fact that we are what we are we're not as good as we were last year.\",\n",
       "  0),\n",
       " (\"We're not as bad as we played form of the Season.\", 0),\n",
       " (\"We're somewhere in between.\", 0),\n",
       " (\"I think we're a playoff team were starting to turn a stuff around right now.\",\n",
       "  0),\n",
       " ('Yeah.', 0),\n",
       " ('No, I believe I do believe I will say that.', 1),\n",
       " (\"It's weird because I feel like in the dog days of the season when you're in like December January and you're sucking ass.\",\n",
       "  0),\n",
       " (\"It's so hard to remain calm.\", 0),\n",
       " (\"But now that it's like there's there's like a light at the end of the tunnel and possibly playoff time.\",\n",
       "  0),\n",
       " (\"I feel like now it's like everything is good.\", 0),\n",
       " ('Yeah for the most part.', 0),\n",
       " (\"I don't know like we're the thing is it all signs point to that were trending up.\",\n",
       "  0),\n",
       " ('Yeah, and we made it through listen some teams tragic suck ass here and Miss Laos.',\n",
       "  0),\n",
       " (\"Stork Lee some teams Trend in Surge late in the season, but they're coming out from the bottom of the standings and it's too late.\",\n",
       "  0),\n",
       " ('We were able to keep her head above water the whole season, even though we sucked ass been able to keep our head above water water over a racist coat incident our best defenseman or collapsing on the ice.',\n",
       "  0),\n",
       " ('I mean, what else happened something else happened?', 0),\n",
       " ('You may want to ask Johnny gaudreau has been terrible you want to ask you is that why best defenseman this season I said this season right?',\n",
       "  0),\n",
       " ('You just need your body best defenseman this season.', 0),\n",
       " (\"I mean we've had Giordano has been hurt Monahan and drove not open them right there regular selves.\",\n",
       "  0),\n",
       " (\"It's like we've overcome so  Shit this year and we've come through it relatively.\",\n",
       "  0),\n",
       " (\"Okay, I'm fully back in love with this team.\", 0),\n",
       " ('It helps that the Pacific Division is probably the weeks division of definitely helps definitely helps.',\n",
       "  0),\n",
       " (\"Well, it's so funny because you texted me something to somebody to the other day.\",\n",
       "  0),\n",
       " (\"It's like Oilers fans right now or like the Oilers have 80 points there Stanley Cup contenders, but the Flames have 77 points morning make the playoffs make the playoffs and crazily enough if  if you check the standings as of right now, the Minnesota goddamn wild are in a playoff spot.\",\n",
       "  0),\n",
       " (\"Yeah, it's insane.\", 0),\n",
       " ('Well, you saw it coming probably three weeks ago.', 0),\n",
       " ('They want a bit of a heater.', 0),\n",
       " (\"They got themselves back in the race and they had game they've had games in hand.\",\n",
       "  0),\n",
       " ('You saw it coming.', 0),\n",
       " ('I like the wild.', 1),\n",
       " (\"I've always liked the Wild and I'd I said they make the laughs.\", 0),\n",
       " (\"I still I still think they didn't have a tough time of it.\", 0),\n",
       " (\"Like so only in by one point Vancouver's got a game in hand.\", 0),\n",
       " ('So you think they will make it they they seem to be trending in surging right now.',\n",
       "  0),\n",
       " (\"I mean, they're still like 15 14 games left.\", 0),\n",
       " (\"The thing is is like I don't know man.\", 0),\n",
       " (\"They're the same position as Carrie where it's like it's their spot to lose.\",\n",
       "  0),\n",
       " ('Yeah.', 0),\n",
       " ('We used to play a good hockey from here on in when a handful of games.', 0),\n",
       " (\"I would say it would be it would be like Bizarro world if Edmonton Calgary Minnesota Vancouver made the playoffs in Nashville Winnipeg didn't but it's it looks like that's probably yeah, but it's gonna happen just not because natural is starting to fall back now Winnipeg starting to fall back now, I don't think these guys can keep pace.\",\n",
       "  0),\n",
       " (\"Dude, it's good.\", 0),\n",
       " (\"I'm glad you know what Nashville needs to miss the playoffs because they need to learn a lesson about doing dumb shit, like signing mattress into a huge contract UK Subban.\",\n",
       "  0),\n",
       " (\"Yeah, and then of course, there's the Arizona Coyotes in the mix as well.\",\n",
       "  0),\n",
       " ('The last team there tonight.', 0),\n",
       " (\"We'll be telling if like a winning a regulation win against Arizona tonight.\",\n",
       "  0),\n",
       " ('Pretty much puts enough separation between you and them that things are looking good.',\n",
       "  0),\n",
       " ('Yeah, I would agree.', 0),\n",
       " (\"All right, let's talk about that game.\", 0),\n",
       " (\"That's a good because it was a weird game.\", 0),\n",
       " (\"Let's go back to this hypothesizing.\", 0),\n",
       " ('Because you and I have been right about a lot of things this season.', 0),\n",
       " (\"Things that we've been wrong about are like small things we can write about a lot of cool things.\",\n",
       "  0),\n",
       " ('We write a lot of a big thanks.', 0),\n",
       " ('Yeah, one of them this prediction of the team will balance themselves out in the second half namely Bonnie and Johnny will research will see them turn things around Johnny has been our best player last what 10 12 games.',\n",
       "  0),\n",
       " (\"Oh 100% he's been great.\", 0),\n",
       " (\"It's been great.\", 0),\n",
       " (\"He's back like one totally back.\", 0),\n",
       " ('I mean he still he still leads the team in scoring as far as I as far as I know right like I think he still is at the top and point.',\n",
       "  0),\n",
       " (\"He's in point per game for the last 25 games when Holmes got the most goals.\",\n",
       "  0),\n",
       " ('but I know I know people are like  how many points did he have?', 0),\n",
       " (\"He's got 50 seized almost got 60.\", 0),\n",
       " (\"I think he's got 57 points.\", 0),\n",
       " (\"That's pretty that's pretty on like it's going to be so he's gonna be on the lower end of his career.\",\n",
       "  0),\n",
       " (\"He's probably on Pace for what 70s probably gonna get 65 70 points, which is still running our pizza career average, but he may just search they see him serger.\",\n",
       "  0),\n",
       " ('Anyways, the point I wanted to make is that we were talking about this last week.',\n",
       "  0),\n",
       " ('Going into this home stretch.', 0),\n",
       " (\"Because the tail of the season so far as you've been excellent on the road do we have the best home record there were certain records or the best away record.\",\n",
       "  0),\n",
       " (\"He definitely won't resist the third best.\", 0),\n",
       " ('Yeah.', 0),\n",
       " ('I know.', 0),\n",
       " (\"It's the best record since January something like that.\", 0),\n",
       " (\"It's probably a third best on the road or 2014 and three so it's not quite as good as you might think.\",\n",
       "  0),\n",
       " (\"It's actually the exact same away record is the Oilers at home and you know, what's weird.\",\n",
       "  0),\n",
       " (\"We're not even as bad at home as I would have thought 1512 and for on home ICE 2014 and three away from the you  Is that Third Way for tonight the third quarter of the Season we want we lost like five in a row.\",\n",
       "  0),\n",
       " (\"Yeah, so it's not like we haven't been good on home ice for sure, but it's not like we've been Dreadful so it's funny how those narratives kind of get going.\",\n",
       "  0),\n",
       " ('Right?', 0),\n",
       " (\"It's like all they've been so good away from the saddledome.\", 0),\n",
       " (\"It's like they've won five more games, but they've also lost two more games away.\",\n",
       "  0),\n",
       " ('Yep, so, but I bet you if you look at  You know being the best road team since January whatever it is.',\n",
       "  0),\n",
       " ('Yeah, you compare their home record to that time.', 0),\n",
       " ('Then you really see that?', 0),\n",
       " ('Well, I think the staff that is like the most mind-boggling.', 0),\n",
       " (\"He's like David Riddick hasn't won a whole night's game since December 12.\",\n",
       "  0),\n",
       " ('Yeah, like holy shit.', 0),\n",
       " (\"Yeah, that's mind-blowing and mind you there's like how many starts is he got and there was the break?\",\n",
       "  0),\n",
       " ('Yeah, etcetera Etc.', 0),\n",
       " ('So it is a little inflated but still like holy shit.', 0),\n",
       " (\"He doesn't want a home game in 2020.\", 0),\n",
       " (\"It's just not so  Bring it back last week, right?\", 0),\n",
       " ('The story was K. You got 11 of your last 15 games at home.', 0),\n",
       " ('Therefore.', 0),\n",
       " ('You should be good shape.', 0),\n",
       " (\"However, they've been so dog shit at home.\", 0),\n",
       " ('Maybe was better for put on the road.', 0),\n",
       " (\"But much to my hypothesis of they're going to turn it around the second half money Johnny you're going to like what I said last week is that they're going to turn it around here at home in these last we have 10 games now.\",\n",
       "  0),\n",
       " (\"And they're going to be good going into the playoffs.\", 0),\n",
       " ('Now I also talked about this.', 0),\n",
       " ('Remember we were doing the pregame liar and that we should do in the pregame of life or Columbus.',\n",
       "  0),\n",
       " ('Yeah, and I said look this always happens.', 0),\n",
       " (\"I don't mean the dog carry you right now, but don't carry me Don Cherry anything you to me.\",\n",
       "  0),\n",
       " ('Collier some some reason  The main thing is the first home game coming off those road trips are usually tough.',\n",
       "  0),\n",
       " ('Use you you happy.', 0),\n",
       " (\"It's like you it's so easy to lay a stinker.\", 0),\n",
       " ('Yeah, right.', 0),\n",
       " (\"And so I'm alive I was like all they gotta do is keep their feet going throughout the first period try not to go down more than one goal.\",\n",
       "  0),\n",
       " (\"If you can you know that you're not going to be able to keep your legs against against them in the first period just because of the whole long road trip yada yada thing.\",\n",
       "  0),\n",
       " (\"And so if you can stay within Arm's Reach by the second period you get legs going you're probably the better team halfway through the game by the third period you should be able to force your will upon the game.\",\n",
       "  0),\n",
       " (\"It didn't necessarily play out exactly like that.\", 0),\n",
       " ('But similarly similarly.', 0),\n",
       " (\"Yeah, and I think the biggest the biggest thing is like when you're trying to turn a tide of momentum.\",\n",
       "  0),\n",
       " (\"Because just like in every game it's all about momentum shifts and momentum swings and I always talked about this how when you're getting hemmed in your own and hemmed in your own and hemmed in your own end.\",\n",
       "  0),\n",
       " ('This team seems to be unable to break that momentum that the other team is generating you.',\n",
       "  0),\n",
       " (\"This is what I'm saying is typically when you do it, it's a giant hit.\", 0),\n",
       " (\"Even after you have to put yourself out of position momentarily it's worth it to break that momentum swing but we haven't really seen that.\",\n",
       "  0),\n",
       " (\"So just like how there's a micro momentum swings in games.\", 0),\n",
       " (\"There's macro momentum swings jury out this throughout the season.\", 0),\n",
       " ('So right now you have your trying to break a negative momentum.', 0),\n",
       " ('Swing of like losing at home stinking at home.', 0),\n",
       " ('And in order to do that.', 0),\n",
       " (\"It's always it never just happens.\", 0),\n",
       " (\"It's always like you have to push through the toughest points.\", 0),\n",
       " (\"There's a threshold you have to get over a hump.\", 0),\n",
       " ('That was what we saw.', 0),\n",
       " ('Against Columbus.', 0),\n",
       " ('Yeah, they did it.', 0),\n",
       " ('It totally did it because they were down to nothing everybody that has a Stockholm Syndrome from this following this season all year lie.',\n",
       "  0),\n",
       " ('I know I turned it off.', 0),\n",
       " ('I had stuff to do mentally checked out quit like fuck this fuck these guys abusive relationship yada yada.',\n",
       "  0),\n",
       " ('But they hung in there.', 0),\n",
       " ('They made it 2-1 Mangia Pawnee Toulon home on you Pawnee putting that that play starts with him how much how many plays in the year?',\n",
       "  0),\n",
       " ('She is ferocious.', 0),\n",
       " ('He is ferocious.', 0),\n",
       " ('Excellent.', 0),\n",
       " ('Did you see you see that?', 0),\n",
       " (\"He's getting some accolades.\", 0),\n",
       " ('Yeah Dimitri filipowicz wrote a little article about him today ESPN.', 0),\n",
       " ('Yep, getting the credit.', 0),\n",
       " ('He deserves man getting the credit.', 0),\n",
       " ('He deserves you make it 2-1 now all of a sudden.', 0),\n",
       " ('Was it nine minutes left?', 0),\n",
       " ('90 minutes nine.', 0),\n",
       " (\"Oh nine days, nine minutes left and everybody's like well, let's see what happens.\",\n",
       "  0),\n",
       " (\"Yeah, because if you want like if you're like me and you turn it off, I turned it back on again.\",\n",
       "  0),\n",
       " (\"So want to say so I'll Lindholm scored you watch them and I was like, I think they're going to tie it up here because they were pressing.\",\n",
       "  0),\n",
       " (\"They're playing good hockey.\", 0),\n",
       " ('Fisher shit did Matthew tkachuk Big Goal Matthew Cooke clutch to clutch.',\n",
       "  0),\n",
       " (\"I can't say that what a beautiful goal.\", 0),\n",
       " ('And by the way, thanks again this time Kelly Rudy.', 0),\n",
       " ('Thanks a lot ruining it Kelly Rudy.', 0),\n",
       " (\"Why are they so obsessed that we chip that were all friends key and when offer it's like it's like, okay.\",\n",
       "  0),\n",
       " (\"Does anybody remember the well, does anybody remember everyone remembers the Jordan a pearly Team Canada World Junior goal and it's like Gord Miller called a lifetime.\",\n",
       "  0),\n",
       " (\"He's  Jordan a police cars, can you believe it and you just let that moment play if you're if you're good broadcaster, but fucking beer McGuire no has to shit over the moment.\",\n",
       "  0),\n",
       " ('So Gord Miller everybody knows this this this happens everybody scores the tying goal.',\n",
       "  0),\n",
       " ('I think it was like, oh eight or o9 with like five seconds left versus the Russians Gord Miller is like joy that like a scars.',\n",
       "  0),\n",
       " (\"Can you believe it and you're supposed to let that let it play.\", 0),\n",
       " (\"And like purifiers like I'm trying to ruin the moment broadcasting color 101 let the moment play Kelly Rudy.\",\n",
       "  0),\n",
       " (\"I don't give a shit if that hit werenski.\", 0),\n",
       " ('Let the moment Play My Guy when Rick balls his Matthew Chuck scores to tie the game.',\n",
       "  0),\n",
       " ('Let it play.', 0),\n",
       " (\"Cassie Campbell and my family's coordinated and goal this plan play out, especially when you're not even sure exactly this one's coming back.\",\n",
       "  0),\n",
       " (\"This one's coming back definitely chores.\", 0),\n",
       " (\"This one's coming back.\", 0),\n",
       " (\"This one's coming back hit they hit the glove Wicked elevator went off a player on the bench trick play anyways, so we're still have to point that out Rudy.\",\n",
       "  0),\n",
       " ('What are you looking at?', 0),\n",
       " (\"I don't know what he's looking at.\", 0),\n",
       " (\"If you're looking at just physics alone for one ski tip that it's not going to go well.\",\n",
       "  0),\n",
       " (\"It went so well, so if you're looking at how could chuck reacted and then that's the other thing watch how check your racks watch out renske reacts did rescue did renske hang his head a bit lookup and disbelief.\",\n",
       "  0),\n",
       " ('I call fuck.', 0),\n",
       " ('I tipped in my own net.', 0),\n",
       " ('No did Chucky go fucking bananas?', 0),\n",
       " ('Ballistic?', 0),\n",
       " ('Like he just fucking square an unreal Taco the tie up the game.', 0),\n",
       " ('Yes.', 0),\n",
       " ('Why do we have to give these broadcasters tips on broadcasting?', 0),\n",
       " (\"anyways  And then over time like I mean that's classic that that that is Calgary Flames see and and this is like when you try to move this whole microcosm thing of like you need to turn the tide, this is just it's a carbon copy of life.\",\n",
       "  0),\n",
       " (\"You're not get any fucking handouts.\", 0),\n",
       " (\"I don't know if you if anybody hasn't recognized this yet, but you're getting a goddamn hand out taking me like 10 years.\",\n",
       "  0),\n",
       " (\"I've completely wasted half of my life.\", 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sentences in sentence_outputs_tuples:\n",
    "    if sentences[1] == 1:\n",
    "        print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transcript_class = pd.DataFrame.from_records(sentence_outputs_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No, I believe I do believe I will say that.', 'I like the wild.',\n",
       "       'But for it was fun.', \"Okay, I don't have it in front of me.\",\n",
       "       \"You can't follow that up with a loss you continue that momentum with another win.\",\n",
       "       \"What's up, everybody?\",\n",
       "       \"And again like we mentioned this yesterday to it's like why Riddick had to Riddick was the one who played the majority of those games.\",\n",
       "       'The guy that is questioned about how much of a workload can handle and the past.',\n",
       "       \"He like you're just playing night after night after night.\",\n",
       "       \"And then even when Talbot starts to like play Lights Out you still start going back to Rick like the I don't like  I feel like more than anything that's fucked with his game.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transcript_class.sort_values(by=1, ascending=False).head(10)[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transcript_class.to_csv(\"output/test_transcript_class.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fecde6947892c09517ced00c50f9815f87f946c7d997fc83be91faa768600f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
