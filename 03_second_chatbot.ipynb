{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Olivia\\anaconda3\\envs\\py38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "\n",
    "# !pip install sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "model_class = AutoModelForSequenceClassification.from_pretrained('morenolq/spotify-podcast-advertising-classification')\n",
    "tokenizer = AutoTokenizer.from_pretrained('morenolq/spotify-podcast-advertising-classification')\n",
    "\n",
    "model = SentenceTransformer('pinecone/distiluse-podcast-nq')\n",
    "\n",
    "# Only run this once, they will be downloaded.\n",
    "nltk.download('stopwords',quiet=True)\n",
    "nltk.download('wordnet',quiet=True)\n",
    "nltk.download('punkt',quiet=True)\n",
    "nltk.download('omw-1.4',quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already created an Elasticsearch client instance 'es'\n",
    "es = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create greetings and greetings function\n",
    "\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"Hello\"]\n",
    "\n",
    "# Checking for greetings\n",
    "def greeting(sentence):\n",
    "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
    "    \n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_search(selected_show):\n",
    "    # Tokenize the user's input using nltk\n",
    "\n",
    "    # Construct the Elasticsearch query to search in specific fields (e.g., show_name, episode_name)\n",
    "    # Customize the index and field names as per your Elasticsearch setup\n",
    "\n",
    "    show_body = {\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": selected_show,  # Combine words with space for multi_match query\n",
    "                \"fields\": [\"show_name\", \"show_description\"],\n",
    "                \"fuzziness\": 1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Execute the Elasticsearch search query\n",
    "    # show_search_results = es.search(index=\"spotify_podcast_transcripts\", body=show_body)\n",
    "    results = es.search(index=\"spotify_podcast_transcripts\", body=show_body)\n",
    "\n",
    "    # Extract relevant information from the search results\n",
    "    hits = results[\"hits\"][\"hits\"]\n",
    "    show_search_results = pd.DataFrame.from_records([hit[\"_source\"] for hit in hits])\n",
    "\n",
    "    return show_search_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chosen_show(show_search_results_df):\n",
    "    try:\n",
    "        unique_shows = show_search_results_df['show_name'].unique()\n",
    "        print(f\"Great, I found {len(unique_shows)} shows for you:\")\n",
    "        [print(f\"{i+1}. {j}\") for i, j in enumerate(unique_shows)]\n",
    "\n",
    "        print(\"\\nPlease type the corresponding number, 1, 2 etc., for the show you want to search for.\")\n",
    "        user_selected_show = input()\n",
    "\n",
    "        show_index = int(user_selected_show)-1\n",
    "        \n",
    "        print(f\"I just want to confirm, you selected {unique_shows[show_index]}, correct?\")\n",
    "        print(\"Please type yes or no:\\n\")\n",
    "\n",
    "        show_confirmation = input().lower()\n",
    "        return show_confirmation, show_index, unique_shows\n",
    "    \n",
    "    except Exception:\n",
    "        print(\"problem with chosen_show\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def episode_response(show_of_interest):\n",
    "\n",
    "    try:\n",
    "        show_of_interest_body = {\n",
    "                                \"query\": {\n",
    "                                    \"term\": {\n",
    "                                    \"show_name.keyword\": show_of_interest\n",
    "                                    }\n",
    "                                },\n",
    "                                \"_source\": [\"episode_name\", \"transcript\"]\n",
    "                                }\n",
    "\n",
    "        results = es.search(index=\"spotify_podcast_transcripts\", body=show_of_interest_body)\n",
    "        # Extract relevant information from the search results\n",
    "        hits = results[\"hits\"][\"hits\"]\n",
    "        episode_hits = pd.DataFrame.from_records([hit[\"_source\"] for hit in hits])\n",
    "        # Execute the Elasticsearch search query\n",
    "        return episode_hits\n",
    "    except:\n",
    "        print(\"problem with episode_response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirm_chosen_episode(episode_hits):\n",
    "    try: \n",
    "        print(\"\\nPlease type the corresponding number, 1, 2 etc., for the episode you want to search for.\")\n",
    "        # # Receive user input and cast it to lowercase\n",
    "        user_selected_episode = input()\n",
    "\n",
    "        episode_index = int(user_selected_episode)-1\n",
    "\n",
    "        name_chosen_episode = episode_hits['episode_name'][episode_index]\n",
    "        print(f\"I just want to confirm, you selected {name_chosen_episode}, correct?\")\n",
    "        print(\"Please type yes or no:\\n\")\n",
    "\n",
    "        user_episode_confirmation = input().lower()\n",
    "\n",
    "        return name_chosen_episode, user_episode_confirmation, episode_index\n",
    "    \n",
    "    except Exception:\n",
    "        print(\"Problem confirm_chosen_episode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcript_response(episode_hits, episode_index):\n",
    "    try: \n",
    "\n",
    "        sent_tokens = episode_hits['sentence_tokens'][episode_index]\n",
    "        \n",
    "        sentence_outputs_tuples = []\n",
    "\n",
    "        for i, s in enumerate(sent_tokens[:200]): \n",
    "            if i==0:\n",
    "                context = \"__START__\"\n",
    "            else:\n",
    "                context = sent_tokens[i-1] \n",
    "            out = tokenizer(context,\n",
    "                            s,\n",
    "                            padding = \"max_length\",\n",
    "                            max_length = 256,\n",
    "                            truncation=True,\n",
    "                            return_attention_mask=True,\n",
    "                            return_tensors = 'pt')\n",
    "            outputs = model_class(**out)\n",
    "            \n",
    "            # probabilities = F.softmax(outputs.logits, dim=1)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            \n",
    "        if predictions.item() == 1:\n",
    "            sentence_outputs_tuples.append((s, predictions.item()))\n",
    "\n",
    "    if len(sentence_outputs_tuples) == 0:\n",
    "        print(\"Sorry, no results found for your query. Please try again\")\n",
    "    else:\n",
    "        print(\"Here are the advertisers for this episode:\")\n",
    "        for sentence_output in sentence_outputs_tuples:\n",
    "            print(sentence_output)\n",
    "\n",
    "    except Exception:\n",
    "        print(\"Problem with transcript_response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirming_the_show (unique_shows, show_index):\n",
    "        \n",
    "    show_of_interest = unique_shows[show_index]\n",
    "    print(show_of_interest)\n",
    "    print(f\"Great, thanks for confirming. Let me search for {show_of_interest} episodes.\")\n",
    "    \n",
    "    # num_episodes_found, episode_hits = corresponding_episodes(show_of_interest)\n",
    "    \n",
    "    episode_hits = episode_response(show_of_interest)\n",
    "    num_episodes_found = len(episode_hits)\n",
    "    print(f\"Great, I found {num_episodes_found} episode(s) for you:\")\n",
    "    [print(f\"{i+1}. {j}\") for i, j in enumerate(episode_hits['episode_name'])]      \n",
    "    \n",
    "    return num_episodes_found, episode_hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Podcast Information Chatbot. \n",
      "I can help you find the advertisers for specific shows or episodes to your favorite podcasts.\n",
      "For your first question, please type the show name. I will search and confirm your input.\n",
      "To end the session, please type the word \"exit\"\n",
      "\n",
      "Great, I found 8 shows for you:\n",
      "1. Vulgar History\n",
      "2. History Hall Park Academy \n",
      "3. Political Scandals \n",
      "4. Four For The Road\n",
      "5. Morning Cup Of Murder\n",
      "6. Biographics: History One Life at a Time\n",
      "7. Jewish History with Rabbi Dr. Dovid Katz \n",
      "8. Return To Tradition\n",
      "\n",
      "Please type the corresponding number, 1, 2 etc., for the show you want to search for.\n",
      "I just want to confirm, you selected Political Scandals , correct?\n",
      "Please type yes or no:\n",
      "\n",
      "Political Scandals \n",
      "Great, thanks for confirming. Let me search for Political Scandals  episodes.\n",
      "Great, I found 1 episode(s) for you:\n",
      "1. Scandal 36: Carroll Hubbard\n",
      "[\"He gave people up to one thousand dollars to make contributions to his wife's campaign as the book of love says if you love someone pay other people to love them too now, whatever do  Looted confidence had convinced Hubbard.\", 'Folks he deserved their money.', 'Hubbard began skimming off large chunks of money from his campaign fund and passing them to his wife.']\n",
      "[0.2571754  0.26241925 0.27371418]\n",
      "Thank you for using the Podcast Information Chatbot. Goodbye.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Chatbot interaction code\n",
    "flag = True\n",
    "print('''Welcome to the Podcast Information Chatbot. \n",
    "I can help you find the advertisers for specific shows or episodes to your favorite podcasts.\n",
    "For your first question, please type the show name. I will search and confirm your input.\n",
    "To end the session, please type the word \"exit\"\\n''')\n",
    "\n",
    "\n",
    "\n",
    "# While the chat is open...\n",
    "while flag:\n",
    "\n",
    "    # Receive user input and cast it to lowercase\n",
    "    user_response = input().lower()\n",
    "\n",
    "    # Handle end of chat\n",
    "    if user_response != 'exit':\n",
    "\n",
    "        # Respond kindly if user responds kindly\n",
    "        if user_response in ['thanks', 'thank you']:\n",
    "            flag = False\n",
    "            print(\"Answer: You are welcome!\")\n",
    "\n",
    "        # Handle user response\n",
    "        else:\n",
    "            # Check if user response includes some existing greeting and choose a random greeting\n",
    "            if greeting(user_response) is not None:\n",
    "                print(\"Answer: \" + greeting(user_response))\n",
    "\n",
    "            else:\n",
    "                # Search in Elasticsearch based on user input\n",
    "                # show_search_results_df, episode_search_results_df = search_show_episode(user_response)\n",
    "                \n",
    "                show_search_results_df = show_search(user_response)\n",
    "\n",
    "                if not show_search_results_df.empty:\n",
    "                    \n",
    "                    show_confirmation, show_index, unique_shows = chosen_show(show_search_results_df)\n",
    "\n",
    "                    if show_confirmation in ['y', \"yes\", \"yea\", \"sure\", \"ok\", \"okay\", \"k\"]:\n",
    "                        \n",
    "                        num_episodes_found, episode_hits = confirming_the_show(unique_shows, show_index)\n",
    "\n",
    "                        if num_episodes_found == 1:\n",
    "\n",
    "                            transcript_response(episode_hits, episode_index=0)\n",
    "\n",
    "                        else:\n",
    "                            name_chosen_episode, user_episode_confirmation, episode_index = confirm_chosen_episode(episode_hits)\n",
    "\n",
    "                            if user_episode_confirmation in ['y', \"yes\", \"yea\", \"sure\", \"ok\", \"okay\", \"k\"]:\n",
    "                                \n",
    "                                print(f\"Okay, let me search for {name_chosen_episode} advertisers:\")\n",
    "                                \n",
    "                                transcript_response(episode_hits, episode_index)\n",
    "\n",
    "                            elif user_episode_confirmation == 'exit':\n",
    "                                flag = False\n",
    "\n",
    "                    elif show_confirmation == 'exit':\n",
    "                        flag = False\n",
    "                        \n",
    "                else:\n",
    "                    print(\"Sorry, no results found for your query. Please try again\")\n",
    "\n",
    "    else:\n",
    "        flag = False\n",
    "        print(\"Thank you for using the Podcast Information Chatbot. Goodbye.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fecde6947892c09517ced00c50f9815f87f946c7d997fc83be91faa768600f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
