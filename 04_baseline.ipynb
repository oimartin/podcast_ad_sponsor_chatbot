{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "\n",
    "# !pip install sentence_transformers\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already created an Elasticsearch client instance 'es'\n",
    "es = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create greetings and greetings function\n",
    "\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"Hello\"]\n",
    "\n",
    "# Checking for greetings\n",
    "def greeting(sentence):\n",
    "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
    "    \n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_search(selected_show):\n",
    "    # Tokenize the user's input using nltk\n",
    "\n",
    "    # Construct the Elasticsearch query to search in specific fields (e.g., show_name, episode_name)\n",
    "    # Customize the index and field names as per your Elasticsearch setup\n",
    "\n",
    "    show_body = {\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": selected_show,  # Combine words with space for multi_match query\n",
    "                \"fields\": [\"show_name\", \"show_description\"],\n",
    "                \"fuzziness\": 1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Execute the Elasticsearch search query\n",
    "    # show_search_results = es.search(index=\"spotify_podcast_transcripts\", body=show_body)\n",
    "    results = es.search(index=\"spotify_podcast_transcripts\", body=show_body)\n",
    "\n",
    "    # Extract relevant information from the search results\n",
    "    hits = results[\"hits\"][\"hits\"]\n",
    "    show_search_results = pd.DataFrame.from_records([hit[\"_source\"] for hit in hits])\n",
    "\n",
    "    return show_search_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chosen_show(show_search_results_df):\n",
    "    try:\n",
    "        unique_shows = show_search_results_df['show_name'].unique()\n",
    "        print(f\"Great, I found {len(unique_shows)} shows for you:\")\n",
    "        [print(f\"{i+1}. {j}\") for i, j in enumerate(unique_shows)]\n",
    "\n",
    "        print(\"\\nPlease type the corresponding number, 1, 2 etc., for the show you want to search for.\")\n",
    "        user_selected_show = input()\n",
    "\n",
    "        show_index = int(user_selected_show)-1\n",
    "        \n",
    "        print(f\"I just want to confirm, you selected {unique_shows[show_index]}, correct?\")\n",
    "        print(\"Please type yes or no:\\n\")\n",
    "\n",
    "        show_confirmation = input().lower()\n",
    "        return show_confirmation, show_index, unique_shows\n",
    "    \n",
    "    except Exception:\n",
    "        print(\"problem with chosen_show\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def episode_response(show_of_interest):\n",
    "\n",
    "    try:\n",
    "        show_of_interest_body = {\n",
    "                                \"query\": {\n",
    "                                    \"term\": {\n",
    "                                    \"show_name.keyword\": show_of_interest\n",
    "                                    }\n",
    "                                },\n",
    "                                \"_source\": [\"episode_name\", \"transcript\"]\n",
    "                                }\n",
    "\n",
    "        results = es.search(index=\"spotify_podcast_transcripts\", body=show_of_interest_body, explain=True)\n",
    "\n",
    "        # Extract relevant information from the search results\n",
    "        hits = results[\"hits\"][\"hits\"]\n",
    "        episode_hits = pd.DataFrame.from_records([hit[\"_source\"] for hit in hits])\n",
    "        \n",
    "        # Execute the Elasticsearch search query\n",
    "        return episode_hits\n",
    "    \n",
    "    except:\n",
    "        print(\"problem with episode_response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirm_chosen_episode(episode_hits):\n",
    "    try: \n",
    "        print(\"\\nPlease type the corresponding number, 1, 2 etc., for the episode you want to search for.\")\n",
    "        # # Receive user input and cast it to lowercase\n",
    "        user_selected_episode = input()\n",
    "\n",
    "        episode_index = int(user_selected_episode)-1\n",
    "\n",
    "        name_chosen_episode = episode_hits['episode_name'][episode_index]\n",
    "        print(f\"I just want to confirm, you selected {name_chosen_episode}, correct?\")\n",
    "        print(\"Please type yes or no:\\n\")\n",
    "\n",
    "        user_episode_confirmation = input().lower()\n",
    "\n",
    "        return name_chosen_episode, user_episode_confirmation, episode_index\n",
    "    \n",
    "    except Exception:\n",
    "        print(\"Problem confirm_chosen_episode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcript_response(episode_of_interest_transcript):\n",
    "    try: \n",
    "        #create list of sentences and words\n",
    "        sent_tokens = nltk.sent_tokenize(episode_of_interest_transcript)# converts to list of sentences\n",
    "        word_tokens = nltk.word_tokenize(episode_of_interest_transcript)# converts to list of words\n",
    "        \n",
    "        ad_question = \"who are the advertisers, sponsors, codes, advertisement, or ads and/or businesses, people, teams thanked?\"\n",
    "        \n",
    "        sent_tokens.append(ad_question)\n",
    "\n",
    "        # add word tokens with tokenized user response\n",
    "        word_tokens = word_tokens + nltk.word_tokenize(ad_question)\n",
    "\n",
    "        chatbot_response = ''\n",
    "        top_responses = []\n",
    "        sentence_encodings = model.encode(sent_tokens, convert_to_tensor=True)# generate sentence transformer embeddings\n",
    "        sentence_encodings = sentence_encodings.cpu()\n",
    "        vals = cosine_similarity(sentence_encodings[-1].reshape(1, -1), sentence_encodings) #the chatbot conversation code\n",
    "\n",
    "\n",
    "        #in the next cell adds the question as the last sentence of the sentence tokens, before calling this response function.\n",
    "        #The code takes the last sentence (which is the question) and gets cosine similarities vs all the sentences in the corpus,\n",
    "        #including itself\n",
    "\n",
    "        #index of the second - fourth highest similarity (the first highest would be the question itself\n",
    "        index_top4 = vals.argsort()[0][-4:-1]\n",
    "\n",
    "        flat = vals.flatten() #reduces dimension of cosine similarity array to be able to sort\n",
    "        flat.sort() #sort the cosine similarity values\n",
    "        top4_cos_sim_val = flat[-4:-1] #get the second highest cosine similarity value.\n",
    "\n",
    "        if(top4_cos_sim_val[-1] == 0): #check the second highest cosine similarity value. If it's zero return the no match response,\n",
    "            #else return highest cosine similarity sentence.\n",
    "            chatbot_response = chatbot_response + \"Sorry, I do not have an answer to your question in my database\"\n",
    "            return chatbot_response\n",
    "        else:\n",
    "            for index in index_top4: \n",
    "                top_result = chatbot_response + sent_tokens[index] #use index of highest cosine similarity to get original sentence\n",
    "                top_responses.append(top_result)\n",
    "        return top_responses, top4_cos_sim_val\n",
    "    except Exception:\n",
    "        print(\"Problem with transcript_response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirming_the_show (unique_shows, show_index):\n",
    "        \n",
    "    show_of_interest = unique_shows[show_index]\n",
    "    print(show_of_interest)\n",
    "    print(f\"Great, thanks for confirming. Let me search for {show_of_interest} episodes.\")\n",
    "    \n",
    "    # num_episodes_found, episode_hits = corresponding_episodes(show_of_interest)\n",
    "    \n",
    "    episode_hits = episode_response(show_of_interest)\n",
    "    num_episodes_found = len(episode_hits)\n",
    "    print(f\"Great, I found {num_episodes_found} episode(s) for you:\")\n",
    "    [print(f\"{i+1}. {j}\") for i, j in enumerate(episode_hits['episode_name'])]      \n",
    "    \n",
    "    return num_episodes_found, episode_hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Podcast Information Chatbot. \n",
      "I can help you find the advertisers for specific shows or episodes to your favorite podcasts.\n",
      "For your first question, please type the show name. I will search and confirm your input.\n",
      "To end the session, please type the word \"exit\"\n",
      "\n",
      "Great, I found 8 shows for you:\n",
      "1. Vulgar History\n",
      "2. History Hall Park Academy \n",
      "3. Political Scandals \n",
      "4. Four For The Road\n",
      "5. Morning Cup Of Murder\n",
      "6. Biographics: History One Life at a Time\n",
      "7. Jewish History with Rabbi Dr. Dovid Katz \n",
      "8. Return To Tradition\n",
      "\n",
      "Please type the corresponding number, 1, 2 etc., for the show you want to search for.\n",
      "I just want to confirm, you selected Political Scandals , correct?\n",
      "Please type yes or no:\n",
      "\n",
      "Political Scandals \n",
      "Great, thanks for confirming. Let me search for Political Scandals  episodes.\n",
      "Great, I found 1 episode(s) for you:\n",
      "1. Scandal 36: Carroll Hubbard\n",
      "[\"He gave people up to one thousand dollars to make contributions to his wife's campaign as the book of love says if you love someone pay other people to love them too now, whatever do  Looted confidence had convinced Hubbard.\", 'Folks he deserved their money.', 'Hubbard began skimming off large chunks of money from his campaign fund and passing them to his wife.']\n",
      "[0.2571754  0.26241925 0.27371418]\n",
      "Thank you for using the Podcast Information Chatbot. Goodbye.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Chatbot interaction code\n",
    "flag = True\n",
    "print('''Welcome to the Podcast Information Chatbot. \n",
    "I can help you find the advertisers for specific shows or episodes to your favorite podcasts.\n",
    "For your first question, please type the show name. I will search and confirm your input.\n",
    "To end the session, please type the word \"exit\"\\n''')\n",
    "\n",
    "\n",
    "\n",
    "# While the chat is open...\n",
    "while flag:\n",
    "\n",
    "    # Receive user input and cast it to lowercase\n",
    "    user_response = input().lower()\n",
    "\n",
    "    # Handle end of chat\n",
    "    if user_response != 'exit':\n",
    "\n",
    "        # Respond kindly if user responds kindly\n",
    "        if user_response in ['thanks', 'thank you']:\n",
    "            flag = False\n",
    "            print(\"Answer: You are welcome!\")\n",
    "\n",
    "        # Handle user response\n",
    "        else:\n",
    "            # Check if user response includes some existing greeting and choose a random greeting\n",
    "            if greeting(user_response) is not None:\n",
    "                print(\"Answer: \" + greeting(user_response))\n",
    "\n",
    "            else:\n",
    "                # Search in Elasticsearch based on user input\n",
    "                # show_search_results_df, episode_search_results_df = search_show_episode(user_response)\n",
    "                \n",
    "                show_search_results_df = show_search(user_response)\n",
    "\n",
    "                # If there are results, confirm the show\n",
    "                if not show_search_results_df.empty:\n",
    "                    \n",
    "                    # If there are multiple results, ask the user to choose one\n",
    "                    show_confirmation, show_index, unique_shows = chosen_show(show_search_results_df)\n",
    "\n",
    "                    # If the user confirms the show, search for advertisers\n",
    "                    if show_confirmation in ['y', \"yes\", \"yea\", \"sure\", \"ok\", \"okay\", \"k\"]:\n",
    "                    \n",
    "                        \n",
    "                        num_episodes_found, episode_hits = confirming_the_show(unique_shows, show_index)\n",
    "\n",
    "                        # If there are multiple episodes, ask the user to choose one    \n",
    "                        if num_episodes_found == 1:\n",
    "\n",
    "                            # \n",
    "                            chatbot_responses, scores = transcript_response(episode_hits['transcript'][0])\n",
    "                            print(chatbot_responses)\n",
    "                            print(scores)\n",
    "\n",
    "                        else:\n",
    "                            name_chosen_episode, user_episode_confirmation, episode_index = confirm_chosen_episode(episode_hits)\n",
    "\n",
    "                            if user_episode_confirmation in ['y', \"yes\", \"yea\", \"sure\", \"ok\", \"okay\", \"k\"]:\n",
    "                                \n",
    "                                print(f\"Okay, let me search for {name_chosen_episode} advertisers:\")\n",
    "                                chatbot_responses, scores = transcript_response(episode_hits['transcript'][episode_index])\n",
    "                                print(chatbot_responses)\n",
    "                                print(scores)\n",
    "\n",
    "                            elif user_episode_confirmation == 'exit':\n",
    "                                flag = False\n",
    "\n",
    "                    elif show_confirmation == 'exit':\n",
    "                        flag = False\n",
    "                        \n",
    "                else:\n",
    "                    print(\"Sorry, no results found for your query. Please try again\")\n",
    "\n",
    "    else:\n",
    "        flag = False\n",
    "        print(\"Thank you for using the Podcast Information Chatbot. Goodbye.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fecde6947892c09517ced00c50f9815f87f946c7d997fc83be91faa768600f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
