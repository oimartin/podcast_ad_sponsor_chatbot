{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "\n",
    "# !pip install sentence_transformers\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Assuming you have already created an Elasticsearch client instance 'es'\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('pinecone/distiluse-podcast-nq')\n",
    "\n",
    "# Only run this once, they will be downloaded.\n",
    "nltk.download('stopwords',quiet=True)\n",
    "nltk.download('wordnet',quiet=True)\n",
    "nltk.download('punkt',quiet=True)\n",
    "nltk.download('omw-1.4',quiet=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pinecone/distiluse-podcast-nq Test on Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-identified episodes to be tested on all chatbots\n",
    "indicator_episodes = [\"spotify:episode:5fG4VlWnWwzAt6mSs0H7lY\", \"spotify:episode:7JG3lLnRoDdOxuqjf14ZkM\",\n",
    "                            \"spotify:episode:3kkhUQJ9DXYs6aSdDmPp2V\", \"spotify:episode:4fJ6Y6IpljKy8FT8DZHx1L\",\n",
    "                            \"spotify:episode:5xBPWxqVCocdBgybmHjr5V\", \"spotify:episode:0X663c1I6j1cehJvy10WMm\", \n",
    "                            \"spotify:episode:61a1JjZO27lGCvCwBaCkpC\", \"spotify:episode:0goWRy1gwB23rQVy8ci7Wa\", \n",
    "                            \"spotify:episode:0BSD8QYmd2mQ1V43uIrU4I\", \"spotify:episode:5xH3cdpkxnJhQjPV22sxKC\",\n",
    "                            \"spotify:episode:0YPvJfSEw0jacPB3IeT37d\", \"spotify:episode:1gnpv26FFvIxpnwVbbRXv1\",\n",
    "                            \"spotify:episode:6rh4J52THn252yi7t11Yqf\", \"spotify:episode:3IfmcM2rcWb82601pkPvCh\",\n",
    "                            \"spotify:episode:5LJ33LdXWhqOu1KNad6D5q\", \"spotify:episode:1AxFBio6NwwG0MAjdCK5gK\",\n",
    "                            \"spotify:episode:3U33mRnDJcXywmBm1hahlL\", \"spotify:episode:57Nzb9H2VRZgHcNFChwbBG\",\n",
    "                            \"spotify:episode:6vRLNVEQ4xqtMxnms3RZh3\", \"spotify:episode:1tN044BhlPjjiluZ7Wo7UL\",\n",
    "                            \"spotify:episode:1fs86N6FLUKW2e5NdX1dF1\", \"spotify:episode:1A4cHtP3wIVQutpCgS7kd7\",\n",
    "                            \"spotify:episode:1Mi90UjG91rm73qvHzcG0t\", \"spotify:episode:3TuC8HZp9VdXtxYMQkJI0m\",\n",
    "                            \"spotify:episode:67v8V9SOXxivYQfAHSsc5f\", \"spotify:episode:3QE8qxHtJg3zMrq03R4GOj\",\n",
    "                            \"spotify:episode:3Vr6AUCTQgVWoE137b4IdB\", \"spotify:episode:4oQZAcd6xnxVA1e2GWaIFb\",\n",
    "                            \"spotify:episode:4sbSs1xtuf8dF3xtb7btUi\", \"spotify:episode:2RoLspr2PQTki51sfMhd20\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indicator_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for spotify:episode:5fG4VlWnWwzAt6mSs0H7lY: 0.52 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:7JG3lLnRoDdOxuqjf14ZkM: 0.38 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:3kkhUQJ9DXYs6aSdDmPp2V: 0.41 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:4fJ6Y6IpljKy8FT8DZHx1L: 0.43 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:5xBPWxqVCocdBgybmHjr5V: 0.5 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:0X663c1I6j1cehJvy10WMm: 0.26 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:61a1JjZO27lGCvCwBaCkpC: 0.46 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:0goWRy1gwB23rQVy8ci7Wa: 0.53 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:0BSD8QYmd2mQ1V43uIrU4I: 0.32 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:5xH3cdpkxnJhQjPV22sxKC: 0.19 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:0YPvJfSEw0jacPB3IeT37d: 0.38 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:1gnpv26FFvIxpnwVbbRXv1: 0.1 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:6rh4J52THn252yi7t11Yqf: 0.32 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:3IfmcM2rcWb82601pkPvCh: 0.14 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:5LJ33LdXWhqOu1KNad6D5q: 0.13 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:1AxFBio6NwwG0MAjdCK5gK: 0.15 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:3U33mRnDJcXywmBm1hahlL: 0.53 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:57Nzb9H2VRZgHcNFChwbBG: 0.12 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:6vRLNVEQ4xqtMxnms3RZh3: 0.28 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:1tN044BhlPjjiluZ7Wo7UL: 0.18 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:1fs86N6FLUKW2e5NdX1dF1: 0.37 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:1A4cHtP3wIVQutpCgS7kd7: 0.59 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:1Mi90UjG91rm73qvHzcG0t: 0.04 minutes\n",
      "(18, 4)\n",
      "Total time for spotify:episode:3TuC8HZp9VdXtxYMQkJI0m: 0.14 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:67v8V9SOXxivYQfAHSsc5f: 0.18 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:3QE8qxHtJg3zMrq03R4GOj: 0.42 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:3Vr6AUCTQgVWoE137b4IdB: 0.4 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:4oQZAcd6xnxVA1e2GWaIFb: 0.16 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:4sbSs1xtuf8dF3xtb7btUi: 0.35 minutes\n",
      "(24, 4)\n",
      "Total time for spotify:episode:2RoLspr2PQTki51sfMhd20: 0.29 minutes\n",
      "(24, 4)\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "of_interest = []\n",
    "\n",
    "# Loop through each episode and extract the relevant information\n",
    "for episode_num, episode in enumerate(indicator_episodes):\n",
    "    episode_ = {\n",
    "        \"query\": {\n",
    "            \"match_phrase\": {\n",
    "                \"_id\": episode,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Search for the episode in the index\n",
    "    results = es.search(index=\"spotify_podcast_transcripts\", body=episode_)\n",
    "\n",
    "    # Extract relevant information from the search results\n",
    "    hits = results[\"hits\"][\"hits\"]\n",
    "\n",
    "    # Extract the episode URI\n",
    "    episode_uri = hits[0]['_id']\n",
    "    sent_tokens = hits[0]['_source']['sentence_tokens']\n",
    "\n",
    "    # Begin timing model runtime\n",
    "    start = time.time()\n",
    "\n",
    "    # Ad question to compare episode transcript sentences to\n",
    "    ad_question = \"who are the advertisers, sponsors, advertisement, or ads and/or businesses, people, teams thanked?\"\n",
    "    \n",
    "    # Append the question to the end of the list of transcript sentences\n",
    "    sent_tokens.append(ad_question)\n",
    "\n",
    "    # Generate sentence transformer embeddings\n",
    "    top_responses = [] \n",
    "    sentence_encodings = model.encode(sent_tokens, convert_to_tensor=True)# generate sentence transformer embeddings\n",
    "    sentence_encodings = sentence_encodings.cpu()\n",
    "\n",
    "    # Calculate cosine similarity between the ad_question sentence and all other sentences\n",
    "    vals = cosine_similarity(sentence_encodings[-1].reshape(1, -1), sentence_encodings) #the chatbot conversation code\n",
    "\n",
    "    #index of the second - fourth highest similarity (the first highest would be the question itself\n",
    "    index_top25 = vals.argsort()[0][-25:-1]\n",
    "\n",
    "    flat = vals.flatten() #reduces dimension of cosine similarity array to be able to sort\n",
    "    flat.sort() #sort the cosine similarity values\n",
    "    top25_cos_sim_val = flat[-25:-1] #get the second highest cosine similarity value.\n",
    "    for index in index_top25:  \n",
    "        top_responses.append(sent_tokens[index])\n",
    "\n",
    "    # end timing runtime\n",
    "    end = time.time()\n",
    "    total_time = round((end-start)/60, 2)\n",
    "    print(f\"Total time for {episode_uri}: {total_time} minutes\")\n",
    "\n",
    "    # Create a DataFrame with the episode information\n",
    "    episode_info = pd.DataFrame({\n",
    "            \"episode_uri\": episode_uri,\n",
    "            \"top_responses\": top_responses,\n",
    "            \"top_scores\": top25_cos_sim_val,\n",
    "            \"total_time\": total_time\n",
    "        })\n",
    "    print(episode_info.shape)\n",
    "    of_interest.append(episode_info)\n",
    "\n",
    "# Create a DataFrame from the list of episode information\n",
    "print(len(of_interest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spotify_episode_5fG4VlWnWwzAt6mSs0H7lY'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of colons in the column names\n",
    "of_interest[0].iloc[0,0].replace(\":\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save each dataframe to a separate excel file\n",
    "for df in of_interest:\n",
    "    episode_uri = df.iloc[0,0].replace(\":\", \"_\")\n",
    "    df.to_excel(f'output/first_chatbot_results/pinecone_{episode_uri}.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine classification results for pinecone/distiluse-podcast-nq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# episodes whose sentences didn't get classified. spotify:episode:0X663c1I6j1cehJvy10WMm, spotify:episode:1Mi90UjG91rm73qvHzcG0t\n",
    "data = pd.read_excel('output/classification_indicator_episodes.xlsx', sheet_name='raw_output')\n",
    "\n",
    "# get the sentences that were classified as advertisement\n",
    "data['advert_sentences'] = data['sentence_predictions'].apply(lambda x: x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all episode excel files\n",
    "path = 'output/Indicator_episode_results/first_chatbot_results/pinecone_'\n",
    "\n",
    "scored_dfs = []\n",
    "\n",
    "# iterate through all episodes\n",
    "for episode in indicator_episodes:\n",
    "\n",
    "    # read in episode excel file\n",
    "    scored_df = pd.read_excel(f'{path}{episode.replace(\":\", \"_\")}.xlsx')\n",
    "\n",
    "    # if there is an empty value, impute with 0\n",
    "    scored_df['y_true'].fillna(0, inplace=True)\n",
    "\n",
    "    # sort by top scores\n",
    "    scored_df.sort_values(by=['top_scores'], ascending=False, inplace=True)\n",
    "    scored_dfs.append(scored_df)\n",
    "\n",
    "# test_episode = 'spotify:episode:7JG3lLnRoDdOxuqjf14ZkM'.replace(':', '_')\n",
    "# test_scored_df = pd.read_excel(f'{path}{test_episode}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_uri</th>\n",
       "      <th>top_responses</th>\n",
       "      <th>top_scores</th>\n",
       "      <th>total_time</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>I'm sorry product right going right dude.</td>\n",
       "      <td>0.220177</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>It doesn't matter if you're 42 or 40 inches wh...</td>\n",
       "      <td>0.207098</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>No, like wide receiver.</td>\n",
       "      <td>0.195982</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>All right all yeah, that's the great unknown a...</td>\n",
       "      <td>0.191011</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>Well every one of those guys are capable of do...</td>\n",
       "      <td>0.190526</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>And if you're a premium user you can download ...</td>\n",
       "      <td>0.181691</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>From your first no, but why me for sports purp...</td>\n",
       "      <td>0.179988</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>Why don't we alternate throwing names out?</td>\n",
       "      <td>0.178179</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>Take a relief following practices that are ope...</td>\n",
       "      <td>0.177365</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>They want to help but now they have to get to ...</td>\n",
       "      <td>0.173050</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>The fun of pro day is finding out which ex-pla...</td>\n",
       "      <td>0.170456</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>Okay that can put you behind when already behi...</td>\n",
       "      <td>0.162241</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>So that's a pretty big job.</td>\n",
       "      <td>0.161031</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>Begin this Thursday, March 5th or reminder to ...</td>\n",
       "      <td>0.160531</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>So well, I mean like we're going on informatio...</td>\n",
       "      <td>0.159821</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>We don't have staff.</td>\n",
       "      <td>0.157986</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>Thanks for joining us Irish Illustrated Insider.</td>\n",
       "      <td>0.157859</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>Pruning or who makes us feel all warm and fuzz...</td>\n",
       "      <td>0.155766</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>It's hard to say gaining athleticism when you'...</td>\n",
       "      <td>0.150007</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>I'm talking about productiveness productive ca...</td>\n",
       "      <td>0.147692</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>Not a firm position and there's guys hurt they...</td>\n",
       "      <td>0.146371</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>I mean it's not it's bucks.</td>\n",
       "      <td>0.144661</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>I mean, those are you know, there's some signi...</td>\n",
       "      <td>0.140691</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:episode:7JG3lLnRoDdOxuqjf14ZkM</td>\n",
       "      <td>A running back takes away one of those spots a...</td>\n",
       "      <td>0.136792</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               episode_uri  \\\n",
       "23  spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "22  spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "21  spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "20  spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "19  spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "18  spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "17  spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "16  spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "15  spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "14  spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "13  spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "12  spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "11  spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "10  spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "9   spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "8   spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "7   spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "6   spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "5   spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "4   spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "3   spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "2   spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "1   spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "0   spotify:episode:7JG3lLnRoDdOxuqjf14ZkM   \n",
       "\n",
       "                                        top_responses  top_scores  total_time  \\\n",
       "23          I'm sorry product right going right dude.    0.220177        0.38   \n",
       "22  It doesn't matter if you're 42 or 40 inches wh...    0.207098        0.38   \n",
       "21                            No, like wide receiver.    0.195982        0.38   \n",
       "20  All right all yeah, that's the great unknown a...    0.191011        0.38   \n",
       "19  Well every one of those guys are capable of do...    0.190526        0.38   \n",
       "18  And if you're a premium user you can download ...    0.181691        0.38   \n",
       "17  From your first no, but why me for sports purp...    0.179988        0.38   \n",
       "16         Why don't we alternate throwing names out?    0.178179        0.38   \n",
       "15  Take a relief following practices that are ope...    0.177365        0.38   \n",
       "14  They want to help but now they have to get to ...    0.173050        0.38   \n",
       "13  The fun of pro day is finding out which ex-pla...    0.170456        0.38   \n",
       "12  Okay that can put you behind when already behi...    0.162241        0.38   \n",
       "11                        So that's a pretty big job.    0.161031        0.38   \n",
       "10  Begin this Thursday, March 5th or reminder to ...    0.160531        0.38   \n",
       "9   So well, I mean like we're going on informatio...    0.159821        0.38   \n",
       "8                                We don't have staff.    0.157986        0.38   \n",
       "7    Thanks for joining us Irish Illustrated Insider.    0.157859        0.38   \n",
       "6   Pruning or who makes us feel all warm and fuzz...    0.155766        0.38   \n",
       "5   It's hard to say gaining athleticism when you'...    0.150007        0.38   \n",
       "4   I'm talking about productiveness productive ca...    0.147692        0.38   \n",
       "3   Not a firm position and there's guys hurt they...    0.146371        0.38   \n",
       "2                         I mean it's not it's bucks.    0.144661        0.38   \n",
       "1   I mean, those are you know, there's some signi...    0.140691        0.38   \n",
       "0   A running back takes away one of those spots a...    0.136792        0.38   \n",
       "\n",
       "    y_true  \n",
       "23       0  \n",
       "22       0  \n",
       "21       0  \n",
       "20       0  \n",
       "19       0  \n",
       "18       0  \n",
       "17       0  \n",
       "16       0  \n",
       "15       0  \n",
       "14       0  \n",
       "13       0  \n",
       "12       0  \n",
       "11       0  \n",
       "10       0  \n",
       "9        0  \n",
       "8        0  \n",
       "7        0  \n",
       "6        0  \n",
       "5        0  \n",
       "4        0  \n",
       "3        0  \n",
       "2        0  \n",
       "1        0  \n",
       "0        0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_scored_df.sort_values(by=['top_scores'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scored_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# take ground truth score and create np.array for y_true scores calculated\n",
    "# true_relevance = scored_df['y_true'].array\n",
    "true_relevance = np.asarray([scored_df['y_true']])\n",
    "display(true_relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13248363, 0.13354959, 0.13725534, 0.1400743 , 0.14035347,\n",
       "        0.14086919, 0.14144759, 0.14327906, 0.14947793, 0.15029049,\n",
       "        0.15133779, 0.15557562, 0.15909256, 0.16203743, 0.16310035,\n",
       "        0.1678865 , 0.17047015, 0.18375085, 0.18465284, 0.1927107 ,\n",
       "        0.203134  , 0.21267931, 0.23191629, 0.24184948]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predicted_scores = scored_df['top_scores'].array\n",
    "predicted_scores = np.asarray([scored_df['top_scores']])\n",
    "display(predicted_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG score:  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "# create a function to calculate the ndcg score to measure\n",
    "# the performance of the model to identify advertisment in a podcast episode transcript\n",
    "ndcg = ndcg_score(true_relevance, predicted_scores)\n",
    "\n",
    "print(\"NDCG score: \", ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.7134154243608393\n",
      "NDCG score:  0.6334896111932239\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.6749855592156191\n",
      "NDCG score:  0.2242438242175755\n",
      "NDCG score:  0.6436409928154081\n",
      "NDCG score:  0.7280404434255173\n",
      "NDCG score:  0.6309297535714573\n",
      "NDCG score:  0.21810429198553116\n",
      "NDCG score:  0.7093946221322694\n",
      "NDCG score:  0.22767024869695263\n",
      "NDCG score:  0.3154648767857289\n",
      "NDCG score:  0.3089957244886703\n",
      "NDCG score:  0.4694080473965761\n",
      "NDCG score:  0.27894294565112965\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.8005641284036986\n",
      "NDCG score:  0.28906482631788766\n",
      "NDCG score:  0.0\n",
      "NDCG score:  0.6350189957328872\n",
      "NDCG score:  0.0\n",
      "Average NDCG score:  0.2833791438796991 for model:  pinecone/distiluse-podcast-nq\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "\n",
    "# ordered greatest to least\n",
    "model_name = 'pinecone/distiluse-podcast-nq'\n",
    "ndcg_scores = []\n",
    "\n",
    "for df in scored_dfs:\n",
    "    true_relevance = np.asarray([df['y_true']])\n",
    "    predicted_scores = np.asarray([df['top_scores']])\n",
    "\n",
    "    ndcg = ndcg_score(true_relevance, predicted_scores)\n",
    "    ndcg_scores.append(ndcg)\n",
    "    print(\"NDCG score: \", ndcg)\n",
    "\n",
    "avg_ndcg_score = np.mean(ndcg_scores)\n",
    "print('Average NDCG score: ', avg_ndcg_score, \"for model: \", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordered least to greatest\n",
    "# scored_episodes = {}\n",
    "# for df in scored_dfs:\n",
    "#     true_relevance = np.asarray([df['y_true']])\n",
    "#     predicted_scores = np.asarray([df['top_scores']])\n",
    "\n",
    "#     ndcg = ndcg_score(true_relevance, predicted_scores)\n",
    "\n",
    "#     print(\"NDCG score: \", ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fecde6947892c09517ced00c50f9815f87f946c7d997fc83be91faa768600f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
